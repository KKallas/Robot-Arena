# Robot Arena Technical Architecture

**Version:** 1.0
**Last Updated:** 2026-01-07

---

## Overview

Robot Arena is a competitive robotics sport with three main pillars (Knowledge Commons, Logistics Operations, League Management) supported by two technical foundations: **Physical Bot Firmware** and **Virtual Arena Simulator**. This document describes the complete technical architecture from hardware to ML models.

---

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Robot Arena Ecosystem                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Knowledge      â”‚  â”‚   Logistics      â”‚  â”‚    League     â”‚ â”‚
â”‚  â”‚   Commons        â”‚  â”‚   Operations     â”‚  â”‚  Management   â”‚ â”‚
â”‚  â”‚                  â”‚  â”‚                  â”‚  â”‚               â”‚ â”‚
â”‚  â”‚ - Match Datasets â”‚  â”‚ - Fleet Rental   â”‚  â”‚ - Events      â”‚ â”‚
â”‚  â”‚ - Strategies     â”‚  â”‚ - Manufacturing  â”‚  â”‚ - Media       â”‚ â”‚
â”‚  â”‚ - ML Models      â”‚  â”‚ - Maintenance    â”‚  â”‚ - Sponsors    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                     â”‚                     â”‚          â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                 â”‚                                â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚                    â”‚                         â”‚                  â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚         â”‚  Physical Firmware  â”‚   â”‚ Virtual Simulator  â”‚       â”‚
â”‚         â”‚                     â”‚   â”‚                    â”‚       â”‚
â”‚         â”‚ - Arduino Motor     â”‚   â”‚ - Python Emulator  â”‚       â”‚
â”‚         â”‚ - M5 Atom Logic     â”‚   â”‚ - Physics Engine   â”‚       â”‚
â”‚         â”‚ - M5 Camera WebUI   â”‚   â”‚ - ML Collision     â”‚       â”‚
â”‚         â”‚ - UART Bus Protocol â”‚   â”‚ - Unreal Render    â”‚       â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Physical Bot Architecture

### Hardware Stack - Shared UART Bus

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SMARS Bot (10cm Platform)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚          Shared UART Bus (921600 baud, broadcast)        â”‚  â”‚
â”‚  â”‚                 All modules listen, selective ignore      â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚    â”‚ M5 Camera   â”‚   â”‚  M5 Atom    â”‚   â”‚  Arduino   â”‚   â”‚  â”‚
â”‚  â”‚    â”‚ ESP32-S3    â”‚   â”‚  ESP32      â”‚   â”‚  Nano/Pro  â”‚   â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚           â”‚                 â”‚                 â”‚          â”‚  â”‚
â”‚  â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚  â”‚                  TX/RX connected to all                  â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  Optional Sensor Modules (also on same bus):             â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚  â”‚
â”‚  â”‚  â”‚  Lidar   â”‚  â”‚  Vision  â”‚  â”‚  Other   â”‚               â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜               â”‚  â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚  Power: 7.4V LiPo (2S) â†’ 5V Buck â†’ All Modules                 â”‚
â”‚  Weight: ~200g total (within competition spec)                  â”‚
â”‚  Cost: â‚¬50-120 depending on configuration                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Insight:** Single UART bus, all modules share TX/RX lines. Each module:
- **Listens** to all packets
- **Ignores** commands not meant for them
- **Transmits** when needed

**Example Traffic Flow:**
```
M5 Camera sends: [STX][0x0F Custom][length][web_command_data][CRC]
  â†’ M5 Atom sees it, parses custom data, executes
  â†’ Arduino sees it, command type is Custom (not 0x01-0x0E), ignores

M5 Atom sends: [STX][0x01 MOVE_FORWARD][duration][speed][CRC]
  â†’ Arduino sees it, executes motor command
  â†’ M5 Camera sees it, logs to SD card

Arduino sends: [STX][0x08 STATUS][battery_voltage][encoder_data][CRC]
  â†’ M5 Atom sees it, updates position estimate
  â†’ M5 Camera sees it, logs to SD card
```

---

### Module Responsibilities

#### **M5 Camera Module (ESP32-S3)**
**Role:** Web Server + Passive Logger

**Hardware:**
- ESP32-S3 (dual-core, 8MB PSRAM)
- OV2640 camera (640x480 @ 30fps)
- SD card slot (for logging)
- UART TX/RX connected to shared bus

**Software:**
- MicroPython with web server
- WiFi Access Point (`Bot-XX`, password protected)
- 3-tab web interface (HTML/CSS/JS served from flash)
- UART packet logger (saves **everything** to SD card)
- Camera streamer (MJPEG over HTTP)
- HTTP API for external control

**Responsibilities:**
- Serve web UI to operators (3-tab interface)
- Stream POV camera feed (640x480 @ 30fps)
- **Listen to all UART traffic**, log everything to SD card
- Parse HTTP requests from operators
- Send commands to bus as **Custom (0x0F)** type
- Store logs to SD card (timestamped, sequential files)

**UART Behavior:**
- **TX:** Sends Custom commands (web UI triggers)
- **RX:** Logs all bus traffic (motor commands, status, sensor data, everything)

---

#### **M5 Atom (ESP32)**
**Role:** Pure Logic Brain

**Hardware:**
- ESP32-PICO-D4 (dual-core, 4MB flash)
- MPU6886 IMU (gyro + accelerometer)
- RGB LED (status indicator)
- UART TX/RX connected to shared bus

**Software:**
- **Vanilla MicroPython** (official ESP32 port)
- **Custom init.py** (your application logic)
  - UART bus listener (filters for Custom commands from Camera)
  - Trigger queue manager
  - Sensor fusion (IMU + encoders â†’ position)
  - ESP-NOW mesh networking (separate from UART bus)
  - User Python code executor

**Responsibilities:**
- Listen to UART bus for Custom (0x0F) commands from M5 Camera
- Execute user-defined Python behaviors (Layer 1)
- Manage trigger queue (queue motor commands with timing)
- Fuse sensor data (IMU + Arduino status â†’ position estimate)
- Coordinate with other bots via ESP-NOW mesh (not UART)
- Send motor commands to bus as standard types (0x01-0x0E)
- Send telemetry/logs back to bus as Custom (0x0F) type

**UART Behavior:**
- **TX:** Sends motor commands (0x01-0x06), status queries (0x08), Custom logs
- **RX:** Listens for Custom (0x0F) from Camera, STATUS (0x08) from Arduino

---

#### **Arduino Nano/Pro (ATmega328P)**
**Role:** Motor Controller

**Hardware:**
- ATmega328P @ 16MHz
- 2x PWM outputs (motor control)
- 2x interrupt pins (encoder inputs)
- UART TX/RX connected to shared bus
- Analog input (battery voltage)

**Software:**
- Arduino C++ (compiled firmware)
- UART bus listener (filters for commands 0x01-0x0E only)
- Motor PWM driver (precise timing)
- Wheel encoder reader (speed feedback)
- Battery monitor (voltage + state of charge)
- Emergency stop handler

**Responsibilities:**
- Listen to UART bus for motor commands (0x01-0x06, 0x0A emergency stop)
- Execute motor commands with precise timing
- Read wheel encoders (odometry)
- Monitor battery state
- Send status updates to bus (0x08 STATUS) at 10Hz

**UART Behavior:**
- **TX:** Sends STATUS (0x08) packets periodically
- **RX:** Listens only for commands 0x01-0x0E, **ignores Custom (0x0F)**

---

### UART Protocol (16-Command Specification)

**Bus Configuration:**
- Baud rate: 921600 (115 KB/s effective)
- Topology: **Shared bus** (all modules TX/RX connected together)
- Flow: Broadcast - everyone hears everything
- Collision avoidance: Simple (modules transmit at different rates)

**Packet Format:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STX  â”‚ Cmd  â”‚ Length â”‚   Payload    â”‚  CRC8   â”‚
â”‚ 1B   â”‚ 1B   â”‚ 1B     â”‚   0-255B     â”‚  1B     â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STX:     0x02 (start of text)
Cmd:     4-bit command ID + 4-bit flags
Length:  Payload byte count
Payload: Command-specific data
CRC8:    Simple checksum (polynomial 0x07)
```

**16 Command Types:**
```
0x00  NOP                    - No operation (keepalive)
0x01  MOVE_FORWARD           - duration_ms (2B), speed (1B)
0x02  MOVE_BACKWARD          - duration_ms (2B), speed (1B)
0x03  TURN_LEFT              - duration_ms (2B), speed (1B)
0x04  TURN_RIGHT             - duration_ms (2B), speed (1B)
0x05  STOP                   - (no payload)
0x06  DRIVE_DIFFERENTIAL     - left_speed (1B), right_speed (1B)
0x07  READ_SENSOR            - sensor_id (1B)
0x08  GET_STATUS             - (response: battery, encoders)
0x09  SET_LED                - r (1B), g (1B), b (1B)
0x0A  EMERGENCY_STOP         - (no payload)
0x0B  CALIBRATE              - calibration_type (1B)
0x0C  PING                   - (no payload)
0x0D  RESET                  - (no payload)
0x0E  RESERVED               - (future use)
0x0F  CUSTOM                 - type (1B), length (2B), data (N bytes)
```

**Command Handling by Module:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Command  â”‚ M5 Camera   â”‚ M5 Atom   â”‚ Arduino    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0x00-0x0Eâ”‚ Log only    â”‚ May listenâ”‚ Execute    â”‚
â”‚ 0x0F     â”‚ Send/Log    â”‚ Execute   â”‚ Ignore     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Custom Command (0x0F) Structure:**
```
Payload format for CUSTOM:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Type     â”‚ Length â”‚ Data           â”‚
â”‚ 1B       â”‚ 2B     â”‚ 0-65535B       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Type IDs:
0x01 - Web UI command (from M5 Camera â†’ M5 Atom)
0x02 - Lidar scan data (from Lidar â†’ M5 Atom, Camera logs)
0x03 - Vision detection (from Vision â†’ M5 Atom, Camera logs)
0x04 - Mesh network packet (M5 Atom â†’ broadcast for logging)
0x05 - Formation coordination (M5 Atom â†’ broadcast)
0x06 - Debug telemetry (M5 Atom â†’ Camera for logging)
...
0xFF - User-defined
```

**Example Custom Type 0x01 (Web UI Command):**
```
M5 Camera receives HTTP POST /api/trigger:
  {command: "move_forward", duration: 2000, speed: 80}

M5 Camera serializes to UART:
  [0x02][0x0F][0x0A][0x01][0x00 0x06]["python_cmd_bytes"][CRC]

  0x0F = Custom command
  0x0A = Total payload length (10 bytes)
  0x01 = Custom type (Web UI command)
  0x00 0x06 = Data length (6 bytes)
  "python_cmd_bytes" = JSON or compact binary encoding

M5 Atom sees this on bus:
  - Checks command type: 0x0F (Custom)
  - Checks custom type: 0x01 (for me!)
  - Parses data: move_forward(2000, 80)
  - Queues trigger

Arduino sees this on bus:
  - Checks command type: 0x0F (Custom, not for me)
  - **Ignores entirely**

M5 Camera sees this on bus (its own packet):
  - Logs to SD card anyway (complete bus record)
```

---

### Software Layers (3-Tier Abstraction)

#### **Layer 0: Low-Level Operations (Firmware)**
Built into Arduino/M5 Atom, exposed via UART protocol.

**Movement Primitives (Arduino executes):**
```python
bot.move_forward(duration_ms, speed_percent)
bot.move_backward(duration_ms, speed_percent)
bot.turn_left(duration_ms, speed_percent)
bot.turn_right(duration_ms, speed_percent)
bot.stop()
bot.drive(left_speed, right_speed)  # -100 to +100
```

**Sensor Reads (M5 Atom provides):**
```python
bot.sensors.imu()          # {gyro_xyz, accel_xyz, temp}
bot.sensors.battery()      # {voltage, percent, time_left} from Arduino STATUS
bot.sensors.distance()     # Ultrasonic/ToF (if equipped, via Custom)
bot.sensors.light()        # Ambient light (if equipped, via Custom)
bot.sensors.camera_frame() # 640x480 JPEG (from M5 Camera web UI)
```

**State & Diagnostics:**
```python
bot.position.get()         # {x, y, theta} from M5 Atom dead reckoning
bot.network.rssi()         # WiFi signal (from M5 Camera)
bot.diagnostics.self_test() # Pre-match validation
bot.get_logs(seconds=120)  # Last 120s (from M5 Camera SD card)
```

---

#### **Layer 1: Python Automation (MicroPython on M5 Atom)**
User-defined in web interface Tab 2, uploaded as Custom (0x0F) command.

**Example: Formation Behaviors**
```python
# Defined in web IDE Tab 2, sent from M5 Camera to M5 Atom
def square_pattern():
    for i in range(4):
        send_to_bus(MOVE_FORWARD, duration=1000, speed=80)
        time.sleep(1.0)
        send_to_bus(TURN_RIGHT, duration=500, speed=60)
        time.sleep(0.5)
    send_to_bus(STOP)

def follow_leader(leader_id):
    while True:
        leader_pos = mesh.get_position(leader_id)  # ESP-NOW, not UART
        angle_to_leader = calculate_heading(position, leader_pos)

        if abs(angle_to_leader) > 10:
            cmd = TURN_LEFT if angle_to_leader > 0 else TURN_RIGHT
            send_to_bus(cmd, duration=100, speed=50)
        else:
            send_to_bus(MOVE_FORWARD, duration=100, speed=70)
        time.sleep(0.1)

def collision_avoidance():
    while True:
        dist = read_distance_sensor()  # From Custom sensor module
        if dist < 20:  # 20cm threshold
            send_to_bus(STOP)
            send_to_bus(TURN_RIGHT, duration=300, speed=80)
        else:
            send_to_bus(MOVE_FORWARD, duration=100, speed=60)
        time.sleep(0.05)

def send_to_bus(cmd, **params):
    """Helper: Send command to shared UART bus"""
    packet = serialize_command(cmd, params)
    uart.write(packet)
```

**UI Result:** Buttons appear in Tab 2 - `[Square Pattern]` `[Follow Leader]` `[Avoid Obstacles]`

---

#### **Layer 2: JavaScript Multi-Bot Orchestration (Browser)**
Runs in browser (web interface Tab 3), sends HTTP to multiple M5 Camera modules.

**Example: Swarm Formations**
```javascript
// Select bots 1-30 via checkboxes
const selectedBots = ['192.168.4.1', '192.168.4.2', ..., '192.168.4.30'];

async function snakeFormation() {
    // Leader moves forward
    await fetch(`http://${selectedBots[0]}/api/trigger`, {
        method: 'POST',
        body: JSON.stringify({command: 'move_forward', duration: 2000, speed: 80})
    });

    // Followers execute follow_leader behavior with 0.5s stagger
    for (let i = 1; i < selectedBots.length; i++) {
        await sleep(500);
        await fetch(`http://${selectedBots[i]}/api/trigger`, {
            method: 'POST',
            body: JSON.stringify({
                command: 'call_function',
                function_name: 'follow_leader',
                args: {leader_id: selectedBots[0]}
            })
        });
    }
}

async function defensiveCircle(centerX, centerY, radius) {
    const angleStep = (2 * Math.PI) / selectedBots.length;

    selectedBots.forEach((botIP, idx) => {
        const angle = idx * angleStep;
        const x = centerX + radius * Math.cos(angle);
        const y = centerY + radius * Math.sin(angle);

        fetch(`http://${botIP}/api/trigger`, {
            method: 'POST',
            body: JSON.stringify({
                command: 'call_function',
                function_name: 'navigate_to',
                args: {x, y}
            })
        });
    });
}
```

---

### Web Interface (3-Tab Design)

Served by M5 Camera module, accessible at `http://192.168.4.1` (WiFi AP).

**Tab 1: Manual Operation**
- Live 640x480 POV camera feed (from M5 Camera OV2640)
- Arrow buttons (â†‘â†“â†â†’) for manual driving
- Real-time sensor readouts (battery, IMU, distance)
- Status indicators (position, UART bus activity, errors)
- All button presses â†’ HTTP POST to `/api/trigger` â†’ Custom (0x0F) to UART bus

**Tab 2: Python Code Editor**
- Syntax-highlighted editor (CodeMirror or Monaco)
- Shows current user functions stored on M5 Atom
- Upload button â†’ sends code via HTTP â†’ Custom (0x0F type 0x01) to M5 Atom
- Execute button â†’ calls function via HTTP â†’ Custom command
- Console output shows results (M5 Atom sends debug via Custom type 0x06, Camera logs and displays)
- Creates buttons for defined functions

**Tab 3: Swarm Orchestration**
- Multi-select bot checkboxes (connects to multiple bot IPs)
- Formation preset buttons
- JavaScript code editor for custom orchestration
- Top-down arena canvas (shows bot positions from mesh network data)
- Execute swarm commands in parallel (multiple HTTP requests to different bots)

---

## Virtual Arena Simulator

### Architecture Overview

The simulator **mirrors the physical bot architecture exactly** including the shared UART bus behavior. Same code runs in both environments. Key innovation: **ML-based collision prediction** trained on real match data.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Virtual Arena (Mac Mini M4)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  60 Virtual Bots (Python Processes)                       â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  Each bot emulates:                                       â”‚  â”‚
â”‚  â”‚  - M5 Camera (Flask web server, same 3-tab UI)           â”‚  â”‚
â”‚  â”‚  - M5 Atom (vanilla MicroPython + init.py, same code)    â”‚  â”‚
â”‚  â”‚  - Arduino (motor commands â†’ physics engine)             â”‚  â”‚
â”‚  â”‚  - Shared UART bus (virtual message queue)               â”‚  â”‚
â”‚  â”‚  - Sensors (simulated with realistic noise)              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Physics Engine (Python)                           â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  - Updates 60 bot positions @ 250ms (4Hz)                â”‚  â”‚
â”‚  â”‚  - Tracks: position, velocity, rotation, acceleration    â”‚  â”‚
â”‚  â”‚  - Collision detection (proximity-based)                 â”‚  â”‚
â”‚  â”‚  - Arena boundaries, goal circles, obstacles             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      ML Collision Predictor (PyTorch)                     â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  Trained on real match data from Knowledge Commons:      â”‚  â”‚
â”‚  â”‚  - Input: pre-collision state (pos, vel, mass, angle)    â”‚  â”‚
â”‚  â”‚  - Output: post-collision state (velocities, damage)     â”‚  â”‚
â”‚  â”‚  - Accuracy: 87% position, 92% damage (validated)        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    Unreal Engine 5 (Rendering)                           â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  - Receives positions via WebSocket @ 250ms              â”‚  â”‚
â”‚  â”‚  - Interpolates movement for 60fps rendering             â”‚  â”‚
â”‚  â”‚  - Generates 61 camera feeds (60 POV + 1 overhead)       â”‚  â”‚
â”‚  â”‚  - Outputs H.264 streams (RTSP or WebRTC)                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚  Competitors connect via:                                        â”‚
â”‚  - VPN (remote access to bot web UIs)                           â”‚
â”‚  - Web interface (same 3-tab UI as physical bots)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Virtual Bot Implementation

**Key Design Principle:** Exact API compatibility with physical bots, including UART bus simulation.

```python
# virtual_bot.py
import queue

# Shared virtual UART bus (all bots subscribe)
virtual_uart_bus = queue.Queue()

class VirtualBot:
    """Emulates M5 Camera + M5 Atom + Arduino stack + shared UART bus"""

    def __init__(self, bot_id, physics_engine, uart_bus):
        self.id = bot_id
        self.physics = physics_engine
        self.uart_bus = uart_bus  # Shared message queue

        self.position = [0, 0, 0]  # x, y, theta
        self.velocity = [0, 0]

        # Emulate M5 Atom user functions (Layer 1)
        self.user_functions = {}

        # Virtual SD card log
        self.uart_log = []

        # Start components
        self.start_uart_listener()
        self.start_web_server()

    def start_uart_listener(self):
        """Background thread: listen to shared UART bus (like physical bus)"""
        def listen():
            while True:
                packet = self.uart_bus.get()  # Block until message

                # M5 Camera behavior: log everything
                self.uart_log.append(packet)

                # M5 Atom behavior: parse Custom commands
                if packet['cmd'] == 0x0F and packet['custom_type'] == 0x01:
                    # Web UI command for me
                    self.execute_command(packet['data'])

                # Arduino behavior: parse motor commands
                if packet['cmd'] in [0x01, 0x02, 0x03, 0x04, 0x05, 0x06]:
                    self.execute_motor_command(packet)

        threading.Thread(target=listen, daemon=True).start()

    def send_to_bus(self, cmd, **params):
        """Send packet to shared UART bus (all virtual bots hear it)"""
        packet = {
            'sender': self.id,
            'cmd': cmd,
            'params': params,
            'timestamp': time.time()
        }
        self.uart_bus.put(packet)

    # Layer 0 API (same as physical M5 Atom init.py)
    def move_forward(self, duration_ms, speed_percent):
        # Send to UART bus (Arduino emulator will see it)
        self.send_to_bus(0x01, duration=duration_ms, speed=speed_percent)

        # Physics engine executes
        self.physics.apply_force(
            bot_id=self.id,
            direction=self.position[2],
            magnitude=speed_percent / 100.0,
            duration=duration_ms / 1000.0
        )

    def sensors_imu(self):
        # Get true values from physics, add realistic noise
        true_accel = self.physics.get_acceleration(self.id)
        noise = np.random.normal(0, 0.01, 3)  # Match MPU6886 specs
        return {
            'accel': (true_accel + noise).tolist(),
            'gyro': self.physics.get_angular_velocity(self.id).tolist(),
            'temp': 25.0 + np.random.normal(0, 0.5)
        }

    # Web server (emulates M5 Camera)
    def start_web_server(self):
        app = Flask(__name__)

        @app.route('/api/trigger', methods=['POST'])
        def trigger():
            cmd = request.json
            # M5 Camera behavior: send as Custom (0x0F) to UART bus
            self.send_to_bus(0x0F, custom_type=0x01, data=cmd)
            return {'status': 'ok'}

        @app.route('/api/sensors/imu')
        def get_imu():
            return jsonify(self.sensors_imu())

        @app.route('/api/camera')
        def camera_feed():
            # Generate synthetic POV frame from Unreal
            frame = self.physics.unreal_bridge.get_pov(self.id)
            return Response(frame, mimetype='image/jpeg')

        @app.route('/api/logs')
        def get_logs():
            # Return UART log (like reading SD card)
            return jsonify(self.uart_log[-1200:])  # Last 120s @ 10Hz

        @app.route('/')
        def index():
            # Serve same 3-tab HTML as physical bot
            return render_template('index.html')

        # Run on unique port per bot
        threading.Thread(
            target=lambda: app.run(host='0.0.0.0', port=8000 + self.id, threaded=True),
            daemon=True
        ).start()
```

---

### ML Collision Predictor

**The Killer Feature:** Proves value of Knowledge Commons dataset.

**Training Pipeline:**
```python
# ml_collision_predictor.py
import torch
import torch.nn as nn

class CollisionPredictor(nn.Module):
    """
    Predicts post-collision state from pre-collision state.
    Trained on real Arena match data from Knowledge Commons.
    """

    def __init__(self):
        super().__init__()
        # Input: [pos_A(2), vel_A(2), mass_A(1),
        #         pos_B(2), vel_B(2), mass_B(1),
        #         collision_angle(1)] = 11 features
        self.fc1 = nn.Linear(11, 128)
        self.fc2 = nn.Linear(128, 128)
        self.fc3 = nn.Linear(128, 64)
        # Output: [vel_A_post(2), vel_B_post(2),
        #          damage_A(1), damage_B(1)] = 6 values
        self.fc4 = nn.Linear(64, 6)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = torch.relu(self.fc3(x))
        return self.fc4(x)

# Training from Knowledge Commons data
def load_collision_data():
    """
    Load from /01-knowledge-commons/ml-datasets/match-replays/
    Parse UART logs from M5 Camera SD cards
    """
    collisions = []

    for log_file in glob('/path/to/knowledge-commons/ml-datasets/uart-logs/*.log'):
        # Parse UART packets
        packets = parse_uart_log(log_file)

        # Reconstruct bot positions from STATUS packets
        positions = reconstruct_positions(packets)

        # Detect collisions (sudden velocity changes)
        for t in range(len(positions) - 1):
            for i in range(60):
                for j in range(i+1, 60):
                    dist = np.linalg.norm(positions[t][i] - positions[t][j])
                    if dist < 0.1:  # Collision detected
                        collisions.append({
                            'pre': extract_pre_state(positions[t], i, j),
                            'post': extract_post_state(positions[t+1], i, j),
                            'log_file': log_file,
                            'timestamp': t
                        })

    return collisions

# Train model
model = CollisionPredictor()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
criterion = nn.MSELoss()

collision_data = load_collision_data()
# ... training loop ...

torch.save(model.state_dict(), 'collision_predictor_v1.pth')
```

**Usage in Simulator:**
```python
# When collision detected in physics engine
if distance(bot_A, bot_B) < 0.1:
    # Prepare input for ML model
    input_state = torch.tensor([
        bot_A.position[0], bot_A.position[1],
        bot_A.velocity[0], bot_A.velocity[1],
        bot_A.mass,
        bot_B.position[0], bot_B.position[1],
        bot_B.velocity[0], bot_B.velocity[1],
        bot_B.mass,
        collision_angle
    ])

    # Predict outcome using real match data
    predicted = collision_model(input_state)

    # Apply to virtual bots
    bot_A.velocity = predicted[0:2].numpy()
    bot_B.velocity = predicted[2:4].numpy()
    bot_A.damage += predicted[4].item()
    bot_B.damage += predicted[5].item()

    # Log to virtual UART bus (for consistency)
    virtual_uart_bus.put({
        'cmd': 0x0F,
        'custom_type': 0x06,  # Debug telemetry
        'data': f'Collision: bot_{bot_A.id} + bot_{bot_B.id}'
    })
```

---

### Unreal Engine Integration

**Position Stream Protocol (WebSocket):**
```json
// Sent every 250ms to Unreal Engine
{
  "timestamp": 1704657600000,
  "bots": [
    {
      "id": 1,
      "position": {"x": 1.23, "y": 0.87, "z": 0.0},
      "rotation": {"pitch": 0, "yaw": 45, "roll": 0},
      "velocity": {"x": 0.5, "y": 0.3}
    },
    // ... 59 more bots
  ],
  "arena_state": {
    "time_remaining": 67.5,
    "red_score": 12,
    "blue_score": 15
  }
}
```

**Unreal receives this @ 4Hz, interpolates to 60fps for smooth rendering.**

**Camera Outputs:**
- 60 POV cameras (one per bot, 640x480 @ 30fps, matches physical OV2640)
- 1 overhead camera (top-down arena view, 1920x1080 @ 60fps)
- H.264 encoding via FFmpeg
- Streamed via RTSP or WebRTC

---

## Dataset Flywheel: Physical â†” Virtual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Data Flywheel                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Physical Matches (Real Arena)
    â†“
UART Logs (M5 Camera SD cards) + Camera Feeds
    â†“
Knowledge Commons Upload
    â†“
Extract Collision Events from UART logs
    â†“
Train ML Collision Model
    â†“
Deploy to Virtual Simulator
    â†“
Virtual Matches (Validation + Synthetic Data)
    â†“
Publish Sim-to-Real Accuracy Metrics
    â†“
Attracts Dataset Licensees (proof of quality)
    â†“
More Revenue â†’ Larger Prize Pools
    â†“
More Competitors â†’ More Physical Matches
    â†“
(Loop: Better dataset â†’ Better models â†’ Better sim)
```

---

## System Requirements

### Physical Bot (Per Unit)

**Hardware:**
- Arduino Nano: â‚¬3-5
- M5 Atom ESP32: â‚¬12-15
- M5 Camera ESP32-S3: â‚¬15-20
- Motors + driver: â‚¬8-10
- Battery (7.4V 1000mAh): â‚¬8-12
- Chassis (3D printed): â‚¬5-8
- **Total: â‚¬50-70 per bot**

**Software:**
- Arduino IDE (C++ compilation)
- MicroPython (vanilla ESP32 port + your init.py for M5 Atom)
- MicroPython (web server for M5 Camera)
- Web UI (HTML/CSS/JS served from M5 Camera flash)

---

### Virtual Simulator (Mac Mini M4)

**Hardware Requirements:**
- Mac Mini M4 (base model sufficient)
- 32GB unified memory recommended
- 1TB SSD (for Unreal assets + match replays)
- 10Gbe networking (optional, for multi-Mac scaling)

**Software Requirements:**
- Python 3.11+ (physics engine, bot emulator)
- PyTorch 2.0+ (ML collision model)
- Unreal Engine 5.3+ (rendering)
- Flask (bot web servers, 60 instances)
- FFmpeg (H.264 encoding)
- Redis (virtual UART bus message queue)

**Performance Targets:**
- 60 virtual bots @ 250ms physics updates âœ…
- Unreal rendering @ 60fps âœ…
- 61 H.264 streams (60 POV + 1 overhead) âš ï¸ (may need GPU offload)
- <500ms end-to-end latency (competitor action â†’ video feedback) âœ…

---

## Integration Points

### Knowledge Commons
- Physical bots upload UART logs (from M5 Camera SD cards)
- Collision events extracted from logs
- ML models trained on collision dataset
- Sim-to-real validation metrics published
- Virtual matches contribute synthetic data (marked as simulated)

### Logistics Operations
- Firmware deployment to rental fleets
- SD card extraction for data upload (M5 Camera modules)
- Quality control (validate UART logging works)
- Bounty verification (test in simulator before physical demo)

### League Management
- Virtual tournaments (online competitions)
- Practice matches (off-season engagement)
- Qualifying rounds (screen for physical events)
- Education programs (simulator for schools without hardware)

---

## Development Roadmap

### Phase 1: Physical Bot Firmware (Months 1-3)
- UART protocol specification (16 commands)
- Arduino motor controller (listens for 0x01-0x0E)
- M5 Atom init.py (vanilla MicroPython + custom logic, listens for Custom 0x0F)
- M5 Camera web server (sends Custom 0x0F, logs all traffic)
- Integration testing on shared UART bus

### Phase 2: Virtual Simulator Core (Months 4-6)
- Python physics engine (250ms updates)
- Virtual UART bus (shared message queue)
- MicroPython API emulator (runs same init.py)
- Flask web servers (60 instances, same UI as physical)
- Basic Unreal scene

### Phase 3: ML Integration (Months 7-9)
- Extract collision data from Knowledge Commons UART logs
- Train collision predictor model
- Integrate into simulator
- Validate sim-to-real accuracy

### Phase 4: Production Ready (Months 10-12)
- H.264 streaming infrastructure
- Tournament management system
- Full documentation
- Deploy to Mac Mini M4

---

## Success Metrics

### Technical
- Physical bot: <1ms trigger timing precision âœ…
- Simulator: 87%+ position prediction accuracy ğŸ¯
- API compatibility: 100% (same init.py runs on both) ğŸ¯
- Uptime: 99%+ for virtual arena ğŸ¯

### Business
- Dataset licensing: Simulator proves value â†’ higher prices
- Global reach: Virtual competitions expand participant base
- Practice engagement: 10x more virtual matches than physical
- Research impact: Sim-to-real papers published using dataset

---

## Conclusion

This architecture creates a **complete ecosystem** where physical and virtual robotics competitions reinforce each other:

1. **Physical matches** generate high-quality real-world data (UART logs)
2. **ML models** learn physics from this data (collision prediction)
3. **Virtual simulator** makes competition globally accessible
4. **Sim-to-real validation** proves dataset quality
5. **More licensees** fund larger prize pools
6. **More competitors** generate more data
7. **Loop repeats**, improving both physical and virtual systems

**Key Simplification:**
- M5 Camera: Web server + UART logger (dumb terminal)
- M5 Atom: Vanilla MicroPython + init.py (all logic)
- Arduino: Motor controller (precise timing)
- **Shared UART bus**: All modules listen, selective ignore based on command type

**Key Innovation:** ML-based collision prediction trained on real matches creates a unique moatâ€”no other robotics competition can claim their simulator is validated against thousands of real-world collisions extracted from complete UART bus logs.

The **Mac Mini M4** is ideal for the simulator: unified memory handles 60 bots + Unreal + ML inference efficiently, while Metal acceleration speeds up both physics and rendering.
